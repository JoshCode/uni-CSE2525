{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "RUN_TESTS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function implementations\n",
    "## Non-negative Matrix Factorisation implementation\n",
    "### Provided design specification\n",
    "Implement the `nmf()` subroutine in the provided code base. This function takes as input a matrix `X`, the number of required components `n` (“number of features” from the lecture), a maximum number of iterations, and an error tolerance threshold. It returns two matrices `W` and `H` (with width/height `n`) such that `WH` approximates `X`.\n",
    "\n",
    "Use the algorithm from the lecture slides as the algorithm to compute `W` and `H`. For more information about it, you can read about it here.\n",
    "\n",
    "If at a certain point in the algorithm the reconstruction error of each consecutive iteration is less than `tol`, then you can stop early.\n",
    "\n",
    "`Hint: if at some place of the algorithm it's possible for a division by 0 to happen, add 1e-9 to the denominator.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-negative matrix factorisation implementation and tests\n",
    "\n",
    "RUN_TESTS = True\n",
    "\n",
    "def nmf(X: pd.DataFrame, n_components: int, max_iter: int=1000, tol: float=1e-3):\n",
    "  \"\"\"\n",
    "  Decomposes the original sparse matrix X into two matrices W and H. \n",
    "  \"\"\"\n",
    "  # Initialize W and H with random non-negative values\n",
    "  W = np.random.rand(X.shape[0], n_components)\n",
    "  H = np.random.rand(n_components, X.shape[1])\n",
    "\n",
    "  # START ANSWER\n",
    "  \n",
    "  # END ANSWER\n",
    "\n",
    "  return W, H\n",
    "\n",
    "if RUN_TESTS:\n",
    "    import unittest\n",
    "    \n",
    "    class TestSolution(unittest.TestCase):\n",
    "        def setUp(self):\n",
    "            np.random.seed(42)\n",
    "\n",
    "        def test_2_by_2(self):\n",
    "            col1 = [1, 1]\n",
    "            col2 = [0, 0]\n",
    "            sparse_matrix = pd.DataFrame(list(zip(col1, col2)))\n",
    "            w, h = nmf(sparse_matrix, 4, 10)\n",
    "            reconstructed_matrix = pd.DataFrame(data=np.dot(w, h),\n",
    "                                                index=sparse_matrix.index,\n",
    "                                                columns=sparse_matrix.columns)\n",
    "            pd.testing.assert_frame_equal(sparse_matrix, reconstructed_matrix, check_dtype=False)\n",
    "\n",
    "        def test_3_by_3(self):\n",
    "            col1 = [1, 1, 0]\n",
    "            col2 = [0, 0, 0]\n",
    "            col3 = [0, 1, 0]\n",
    "            sparse_matrix = pd.DataFrame(list(zip(col1, col2, col3)))\n",
    "            w, h = nmf(sparse_matrix, 5, 50)\n",
    "            reconstructed_matrix = pd.DataFrame(data=np.dot(w, h),\n",
    "                                                index=sparse_matrix.index,\n",
    "                                                columns=sparse_matrix.columns)\n",
    "            pd.testing.assert_frame_equal(sparse_matrix, reconstructed_matrix, check_dtype=False, atol=0.05)\n",
    "\n",
    "        def test_3_by_2(self):\n",
    "            col1 = [0, 1, 0]\n",
    "            col2 = [0, 0, 1]\n",
    "            sparse_matrix = pd.DataFrame(list(zip(col1, col2)))\n",
    "            w, h = nmf(sparse_matrix, 5, 50)\n",
    "            reconstructed_matrix = pd.DataFrame(data=np.dot(w, h),\n",
    "                                                index=sparse_matrix.index,\n",
    "                                                columns=sparse_matrix.columns)\n",
    "            pd.testing.assert_frame_equal(sparse_matrix, reconstructed_matrix, check_dtype=False, atol=0.05)\n",
    "\n",
    "        def test_5_by_5(self):\n",
    "            col1 = [0, 1, 0, 0, 0]\n",
    "            col2 = [0, 0, 1, 1, 0]\n",
    "            col3 = [0, 0, 0, 0, 0]\n",
    "            col4 = [0, 1, 0, 0, 0]\n",
    "            col5 = [1, 0, 0, 0, 0]\n",
    "            sparse_matrix = pd.DataFrame(list(zip(col1, col2, col3, col4, col5)))\n",
    "            w, h = nmf(sparse_matrix, 5, 50)\n",
    "            reconstructed_matrix = pd.DataFrame(data=np.dot(w, h),\n",
    "                                                index=sparse_matrix.index,\n",
    "                                                columns=sparse_matrix.columns)\n",
    "            pd.testing.assert_frame_equal(sparse_matrix, reconstructed_matrix, check_dtype=False, atol=0.05)\n",
    "\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinHashing implementation\n",
    "### Provided design specification\n",
    "Implement the `compute_signature()` subroutine in the provided code base. This function takes as input a list of `k` `HashFunction` and a list of `n` sets of integers, representing which `ids` each user has liked.\n",
    "\n",
    "Have a look in the library to see how `HashFunction` is defined.\n",
    "\n",
    "It should return the minhash signature for the given input, when applying the provided hash functions. The signature should be of size `k x n`, where each column of the signature matrix represents the index of the user’s liked ids, and the rows represent the index of each hash function.\n",
    "\n",
    "The goal is for similar sets of liked `ids` to have similar columns in the signature matrix. See the tests for an example of what’s expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "ids = [{1, 2, 3, 4}, {1}, {4, 5}, {1, 2, 3}, {1}]\n",
    "space = set().union(*ids)\n",
    "a = sorted(space)\n",
    "\n",
    "print(np.full((0, 0), sys.maxsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_identical_sets (__main__.TestSolution.test_identical_sets) ... ok\n",
      "test_multiple_sets (__main__.TestSolution.test_multiple_sets) ... ok\n",
      "test_mutually_exclusive_sets (__main__.TestSolution.test_mutually_exclusive_sets) ... ok\n",
      "test_non_consecutive_set (__main__.TestSolution.test_non_consecutive_set) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Minhashing implementation and tests\n",
    "class HashFunction:\n",
    "    \"\"\"\n",
    "    Library class HashFunction. Do not change\n",
    "    This HashFunction class can be used to create an unique hash given an alpha and beta.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha, beta):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def hashf(self, x: float, n: int):\n",
    "        \"\"\"\n",
    "        Returns a hash given integers x and n.\n",
    "        :param x: The value to be hashed\n",
    "        :param n: The number of unique ids of all sets (modulo)\n",
    "        :return: The hashed value x given alpha and beta\n",
    "        \"\"\"\n",
    "        \n",
    "        hash_value = 0\n",
    "        hash_value =  (self.alpha * x + self.beta) % n\n",
    "        return hash_value\n",
    "\n",
    "def compute_signature(hashes: list[HashFunction], ids: list[set[int]]):\n",
    "    \"\"\"\n",
    "    This function will calculate the MinHash signature matrix from our sets of ids\n",
    "    using the list of hash functions (hashes)\n",
    "    :param hashes: The list of hash functions of arbitrary length\n",
    "    :param ids: The list of sets of ids\n",
    "    :return: The MinHash signature matrix for the given sets of ids\n",
    "    \"\"\"\n",
    "    \n",
    "    result = np.full((len(hashes), len(ids)), sys.maxsize)\n",
    "    space = set().union(*ids)\n",
    "    sorted_space = sorted(space)\n",
    "    \n",
    "    # START ANSWER\n",
    "    if len(hashes) == 0 or len(ids) == 0:\n",
    "        return np.full((len(hashes), len(ids)), sys.maxsize)\n",
    "    \n",
    "    max_id = max(sorted_space)\n",
    "    number_distinct_ids = len(sorted_space)\n",
    "    \n",
    "    # Initialise an existence matrix of max_id x number of id sets\n",
    "    # The matrix is 0-indexed, for index 0 matches `id` = 1\n",
    "    existence_matrix = np.full((number_distinct_ids, len(ids)), -1)\n",
    "\n",
    "    # Populate existence matrix\n",
    "    for i in range(0, existence_matrix.shape[0]):\n",
    "        for j in range(0, existence_matrix.shape[1]):\n",
    "            # Existence matrix entry (`i`, `j`) will be 1 if set `j` contains id (= i + 1)\n",
    "            # Else, it will be 0\n",
    "            id = sorted_space[i]\n",
    "            column_set = ids[j]\n",
    "            existence_matrix[i, j] = 1 if id in column_set else 0\n",
    "\n",
    "    # Calculate hash signature\n",
    "    for i in range(0, existence_matrix.shape[0]):\n",
    "        calculated_hashes = []\n",
    "        # First, we pre-calculate the hashes for the current row index `i`\n",
    "        for hashing_function in hashes:\n",
    "            calculated_hashes.append(hashing_function.hashf(i, number_distinct_ids))\n",
    "\n",
    "        # For every column in the existence matrix, if the entry is 1 (column j contains id i + 1)\n",
    "        # Update the hash signature for (`i`, `j`) if the new hash for row i is smaller than any previous hash\n",
    "        for j in range(0, existence_matrix.shape[1]):\n",
    "            if existence_matrix[i, j] == 1:\n",
    "                for result_i in range(0, result.shape[0]):\n",
    "                    result[result_i, j] = min(result[result_i, j], calculated_hashes[result_i])\n",
    "    # END ANSWER\n",
    "    return result\n",
    "\n",
    "if RUN_TESTS:\n",
    "    import unittest\n",
    "\n",
    "    class TestSolution(unittest.TestCase):\n",
    "\n",
    "        def test_multiple_sets(self):\n",
    "            h1 = HashFunction(2, 3)\n",
    "            h2 = HashFunction(4, 2)\n",
    "            h3 = HashFunction(1, 3)\n",
    "            h4 = HashFunction(3, 1)\n",
    "\n",
    "            test_hashes = [h1, h2, h3, h4]\n",
    "\n",
    "            test_sets = [{1, 2, 3, 4}, {1}, {4, 5}, {1, 2, 3}, {1}]\n",
    "            \n",
    "            result = compute_signature(test_hashes, test_sets)\n",
    "            expected = np.array([[0, 3, 1, 0, 3],\n",
    "                                [0, 2, 3, 0, 2],\n",
    "                                [0, 3, 1, 0, 3],\n",
    "                                [0, 1, 0, 1, 1]])\n",
    "            np.testing.assert_array_equal(result, expected)\n",
    "\n",
    "        def test_identical_sets(self):\n",
    "            h1 = HashFunction(2, 3)\n",
    "            h2 = HashFunction(4, 2)\n",
    "            h3 = HashFunction(1, 3)\n",
    "            h4 = HashFunction(3, 1)\n",
    "\n",
    "            test_hashes = [h1, h2, h3, h4]\n",
    "\n",
    "            test_sets = [{2, 3}, {2, 3}, {2, 3}]\n",
    "            \n",
    "            result = compute_signature(test_hashes, test_sets)\n",
    "            expected = np.array([[1, 1, 1],\n",
    "                                [0, 0, 0],\n",
    "                                [0, 0, 0],\n",
    "                                [0, 0, 0]])\n",
    "            np.testing.assert_array_equal(result, expected)\n",
    "\n",
    "        def test_mutually_exclusive_sets(self):\n",
    "            h1 = HashFunction(2, 3)\n",
    "            h2 = HashFunction(4, 2)\n",
    "            h3 = HashFunction(1, 3)\n",
    "\n",
    "            test_hashes = [h1, h2, h3]\n",
    "\n",
    "            test_sets = [{1, 2}, {3, 4}, {5, 6}]\n",
    "            \n",
    "            result = compute_signature(test_hashes, test_sets)\n",
    "            expected = np.array([[3, 1, 1],\n",
    "                                [0, 2, 0],\n",
    "                                [3, 0, 1]])\n",
    "            np.testing.assert_array_equal(result, expected)\n",
    "        \n",
    "        def test_non_consecutive_set(self):\n",
    "            h1 = HashFunction(2, 3)\n",
    "            h2 = HashFunction(4, 2)\n",
    "            h3 = HashFunction(1, 3)\n",
    "            h4 = HashFunction(3, 1)\n",
    "\n",
    "            test_hashes = [h1, h2]\n",
    "\n",
    "            test_sets = [{2, 3, 6}, {2, 6}, {2, 3}, {3, 6}]\n",
    "            \n",
    "            result = compute_signature(test_hashes, test_sets)\n",
    "            expected = np.array([[0, 0, 0, 1],\n",
    "                                 [0, 1, 0, 0]])\n",
    "            np.testing.assert_array_equal(result, expected)\n",
    "\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE2525 Data Mining: Lab 2 - Matrix Decomposition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
